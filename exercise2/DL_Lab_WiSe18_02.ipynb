{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import gzip\n",
    "import os\n",
    "import pickle\n",
    "import json as json\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n",
      "... done loading data\n",
      "(50000, 28, 28, 1)\n",
      "(50000,)\n",
      "(10000, 28, 28, 1)\n",
      "(10000,)\n",
      "(10000, 28, 28, 1)\n",
      "(10000,)\n",
      "./mnist_convnet_modellearningrate_0.1\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './mnist_convnet_modellearningrate_0.1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000017900C398D0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "x_input.shape (128, 28, 28, 1)\n",
      "convlayer1.shape (128, 28, 28, 16)\n",
      "maxpool1.shape (128, 14, 14, 16)\n",
      "convlayer2.shape (128, 14, 14, 16)\n",
      "maxpool2.shape (128, 7, 7, 16)\n",
      "maxpool2_vec.shape (128, 784)\n",
      "denselayer.shape (128, 128)\n",
      "logitslayer.shape (128, 10)\n",
      "labels.shape (128,)\n",
      "sceloss.shape ()\n",
      "tf.estimator.ModeKeys.TRAIN...\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_convnet_modellearningrate_0.1\\model.ckpt-36\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 36 into ./mnist_convnet_modellearningrate_0.1\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.01528495 0.20331107 0.29711345 ... 0.00779517 0.05035382 0.00297374]\n",
      " [0.01065487 0.11887126 0.01927646 ... 0.24473536 0.09332542 0.1210923 ]\n",
      " [0.01670409 0.04941302 0.01415372 ... 0.68674356 0.0540264  0.03543981]\n",
      " ...\n",
      " [0.00278397 0.6965938  0.0239933  ... 0.02537012 0.05980008 0.00861563]\n",
      " [0.41391152 0.00249648 0.06307009 ... 0.01374398 0.0796774  0.00272946]\n",
      " [0.04952716 0.03023872 0.01726833 ... 0.05423934 0.11119634 0.02176556]]\n",
      "INFO:tensorflow:loss = 1.1469426, step = 37\n",
      "INFO:tensorflow:Saving checkpoints for 37 into ./mnist_convnet_modellearningrate_0.1\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.1469426.\n",
      "TRAINING EPOCH... 1\n",
      "<tensorflow.python.estimator.estimator.Estimator object at 0x0000017900C396D8>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "x_input.shape (?, 28, 28, 1)\n",
      "convlayer1.shape (?, 28, 28, 16)\n",
      "maxpool1.shape (?, 14, 14, 16)\n",
      "convlayer2.shape (?, 14, 14, 16)\n",
      "maxpool2.shape (?, 7, 7, 16)\n",
      "maxpool2_vec.shape (?, 784)\n",
      "denselayer.shape (?, 128)\n",
      "logitslayer.shape (?, 10)\n",
      "labels.shape (?,)\n",
      "sceloss.shape ()\n",
      "tf.estimator.ModeKeys.EVAL...\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-10-14:50:31\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_convnet_modellearningrate_0.1\\model.ckpt-37\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-10-14:50:34\n",
      "INFO:tensorflow:Saving dict for global step 37: accuracy = 0.7505, global_step = 37, loss = 0.9646816\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 37: ./mnist_convnet_modellearningrate_0.1\\model.ckpt-37\n",
      "EVAL EPOCH... 1\n",
      "{'accuracy': 0.7505, 'loss': 0.9646816, 'global_step': 37}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "x_input.shape (128, 28, 28, 1)\n",
      "convlayer1.shape (128, 28, 28, 16)\n",
      "maxpool1.shape (128, 14, 14, 16)\n",
      "convlayer2.shape (128, 14, 14, 16)\n",
      "maxpool2.shape (128, 7, 7, 16)\n",
      "maxpool2_vec.shape (128, 784)\n",
      "denselayer.shape (128, 128)\n",
      "logitslayer.shape (128, 10)\n",
      "labels.shape (128,)\n",
      "sceloss.shape ()\n",
      "tf.estimator.ModeKeys.TRAIN...\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_convnet_modellearningrate_0.1\\model.ckpt-37\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 37 into ./mnist_convnet_modellearningrate_0.1\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.50027764 0.00102055 0.05553048 ... 0.0084542  0.09611911 0.00355342]\n",
      " [0.10819922 0.02344001 0.09833616 ... 0.02318527 0.17573966 0.00173778]\n",
      " [0.00815976 0.00191633 0.00520768 ... 0.20700777 0.04863543 0.05484739]\n",
      " ...\n",
      " [0.10879071 0.00271643 0.00404673 ... 0.07318208 0.11035921 0.09474859]\n",
      " [0.27323297 0.00226691 0.045956   ... 0.07510427 0.11617706 0.01845149]\n",
      " [0.02017295 0.2428833  0.06234479 ... 0.02722534 0.19059224 0.01755976]]\n",
      "INFO:tensorflow:loss = 1.026639, step = 38\n",
      "INFO:tensorflow:Saving checkpoints for 38 into ./mnist_convnet_modellearningrate_0.1\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.026639.\n",
      "TRAINING EPOCH... 2\n",
      "<tensorflow.python.estimator.estimator.Estimator object at 0x0000017900C396D8>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "x_input.shape (?, 28, 28, 1)\n",
      "convlayer1.shape (?, 28, 28, 16)\n",
      "maxpool1.shape (?, 14, 14, 16)\n",
      "convlayer2.shape (?, 14, 14, 16)\n",
      "maxpool2.shape (?, 7, 7, 16)\n",
      "maxpool2_vec.shape (?, 784)\n",
      "denselayer.shape (?, 128)\n",
      "logitslayer.shape (?, 10)\n",
      "labels.shape (?,)\n",
      "sceloss.shape ()\n",
      "tf.estimator.ModeKeys.EVAL...\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-10-14:50:36\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_convnet_modellearningrate_0.1\\model.ckpt-38\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-10-14:50:39\n",
      "INFO:tensorflow:Saving dict for global step 38: accuracy = 0.78, global_step = 38, loss = 0.8392948\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 38: ./mnist_convnet_modellearningrate_0.1\\model.ckpt-38\n",
      "EVAL EPOCH... 2\n",
      "{'accuracy': 0.78, 'loss': 0.8392948, 'global_step': 38}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "x_input.shape (128, 28, 28, 1)\n",
      "convlayer1.shape (128, 28, 28, 16)\n",
      "maxpool1.shape (128, 14, 14, 16)\n",
      "convlayer2.shape (128, 14, 14, 16)\n",
      "maxpool2.shape (128, 7, 7, 16)\n",
      "maxpool2_vec.shape (128, 784)\n",
      "denselayer.shape (128, 128)\n",
      "logitslayer.shape (128, 10)\n",
      "labels.shape (128,)\n",
      "sceloss.shape ()\n",
      "tf.estimator.ModeKeys.TRAIN...\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_convnet_modellearningrate_0.1\\model.ckpt-38\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 38 into ./mnist_convnet_modellearningrate_0.1\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.00072304 0.0008053  0.00083303 ... 0.96421844 0.00621198 0.01054271]\n",
      " [0.19543315 0.00051642 0.24487305 ... 0.06453709 0.10294039 0.02535104]\n",
      " [0.00100712 0.82448983 0.02456089 ... 0.01846124 0.05097933 0.00807805]\n",
      " ...\n",
      " [0.00542496 0.00187777 0.0272111  ... 0.22560407 0.10784788 0.21597147]\n",
      " [0.02040628 0.00836402 0.01569716 ... 0.09511123 0.10590283 0.25650495]\n",
      " [0.0058637  0.6694549  0.08874153 ... 0.00802243 0.13333315 0.00362201]]\n",
      "INFO:tensorflow:loss = 0.7971599, step = 39\n",
      "INFO:tensorflow:Saving checkpoints for 39 into ./mnist_convnet_modellearningrate_0.1\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.7971599.\n",
      "TRAINING EPOCH... 3\n",
      "<tensorflow.python.estimator.estimator.Estimator object at 0x0000017900C396D8>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "x_input.shape (?, 28, 28, 1)\n",
      "convlayer1.shape (?, 28, 28, 16)\n",
      "maxpool1.shape (?, 14, 14, 16)\n",
      "convlayer2.shape (?, 14, 14, 16)\n",
      "maxpool2.shape (?, 7, 7, 16)\n",
      "maxpool2_vec.shape (?, 784)\n",
      "denselayer.shape (?, 128)\n",
      "logitslayer.shape (?, 10)\n",
      "labels.shape (?,)\n",
      "sceloss.shape ()\n",
      "tf.estimator.ModeKeys.EVAL...\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-10-14:50:41\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_convnet_modellearningrate_0.1\\model.ckpt-39\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-11-10-14:50:44\n",
      "INFO:tensorflow:Saving dict for global step 39: accuracy = 0.787, global_step = 39, loss = 0.7673814\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 39: ./mnist_convnet_modellearningrate_0.1\\model.ckpt-39\n",
      "EVAL EPOCH... 3\n",
      "{'accuracy': 0.787, 'loss': 0.7673814, 'global_step': 39}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "x_input.shape (128, 28, 28, 1)\n",
      "convlayer1.shape (128, 28, 28, 16)\n",
      "maxpool1.shape (128, 14, 14, 16)\n",
      "convlayer2.shape (128, 14, 14, 16)\n",
      "maxpool2.shape (128, 7, 7, 16)\n",
      "maxpool2_vec.shape (128, 784)\n",
      "denselayer.shape (128, 128)\n",
      "logitslayer.shape (128, 10)\n",
      "labels.shape (128,)\n",
      "sceloss.shape ()\n",
      "tf.estimator.ModeKeys.TRAIN...\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_convnet_modellearningrate_0.1\\model.ckpt-39\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 39 into ./mnist_convnet_modellearningrate_0.1\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.0238025  0.01103525 0.16516933 ... 0.00150706 0.03348102 0.01213755]\n",
      " [0.00879112 0.3234627  0.06491236 ... 0.08562144 0.19778556 0.07418828]\n",
      " [0.13646093 0.0021789  0.01388227 ... 0.00086925 0.02883584 0.0121341 ]\n",
      " ...\n",
      " [0.0014021  0.06628343 0.00474006 ... 0.16984333 0.02526004 0.56573975]\n",
      " [0.04875131 0.03364851 0.2862695  ... 0.00182848 0.0476722  0.02385221]\n",
      " [0.23991118 0.00252643 0.49088746 ... 0.00697999 0.02547058 0.00850299]]\n",
      "INFO:tensorflow:loss = 0.6763101, step = 40\n",
      "INFO:tensorflow:Saving checkpoints for 40 into ./mnist_convnet_modellearningrate_0.1\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.6763101.\n",
      "TRAINING EPOCH... 4\n",
      "<tensorflow.python.estimator.estimator.Estimator object at 0x0000017900C396D8>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "x_input.shape (?, 28, 28, 1)\n",
      "convlayer1.shape (?, 28, 28, 16)\n",
      "maxpool1.shape (?, 14, 14, 16)\n",
      "convlayer2.shape (?, 14, 14, 16)\n",
      "maxpool2.shape (?, 7, 7, 16)\n",
      "maxpool2_vec.shape (?, 784)\n",
      "denselayer.shape (?, 128)\n",
      "logitslayer.shape (?, 10)\n",
      "labels.shape (?,)\n",
      "sceloss.shape ()\n",
      "tf.estimator.ModeKeys.EVAL...\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-10-14:50:46\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_convnet_modellearningrate_0.1\\model.ckpt-40\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-10-14:50:49\n",
      "INFO:tensorflow:Saving dict for global step 40: accuracy = 0.7603, global_step = 40, loss = 0.7737827\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40: ./mnist_convnet_modellearningrate_0.1\\model.ckpt-40\n",
      "EVAL EPOCH... 4\n",
      "{'accuracy': 0.7603, 'loss': 0.7737827, 'global_step': 40}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "x_input.shape (128, 28, 28, 1)\n",
      "convlayer1.shape (128, 28, 28, 16)\n",
      "maxpool1.shape (128, 14, 14, 16)\n",
      "convlayer2.shape (128, 14, 14, 16)\n",
      "maxpool2.shape (128, 7, 7, 16)\n",
      "maxpool2_vec.shape (128, 784)\n",
      "denselayer.shape (128, 128)\n",
      "logitslayer.shape (128, 10)\n",
      "labels.shape (128,)\n",
      "sceloss.shape ()\n",
      "tf.estimator.ModeKeys.TRAIN...\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_convnet_modellearningrate_0.1\\model.ckpt-40\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 40 into ./mnist_convnet_modellearningrate_0.1\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.01101732 0.00005916 0.00873559 ... 0.9424044  0.00835002 0.00766413]\n",
      " [0.10248898 0.00038298 0.28257677 ... 0.1092312  0.08797792 0.02843567]\n",
      " [0.00134487 0.00013511 0.04856912 ... 0.00405952 0.00741281 0.00638342]\n",
      " ...\n",
      " [0.00189984 0.00938251 0.71600646 ... 0.02281757 0.02831015 0.0075174 ]\n",
      " [0.00714936 0.00519862 0.02773478 ... 0.01570788 0.11063286 0.20808025]\n",
      " [0.00270501 0.5622198  0.07427242 ... 0.02633824 0.17371452 0.02386955]]\n",
      "INFO:tensorflow:loss = 1.032735, step = 41\n",
      "INFO:tensorflow:Saving checkpoints for 41 into ./mnist_convnet_modellearningrate_0.1\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.032735.\n",
      "TRAINING EPOCH... 5\n",
      "<tensorflow.python.estimator.estimator.Estimator object at 0x0000017900C396D8>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "x_input.shape (?, 28, 28, 1)\n",
      "convlayer1.shape (?, 28, 28, 16)\n",
      "maxpool1.shape (?, 14, 14, 16)\n",
      "convlayer2.shape (?, 14, 14, 16)\n",
      "maxpool2.shape (?, 7, 7, 16)\n",
      "maxpool2_vec.shape (?, 784)\n",
      "denselayer.shape (?, 128)\n",
      "logitslayer.shape (?, 10)\n",
      "labels.shape (?,)\n",
      "sceloss.shape ()\n",
      "tf.estimator.ModeKeys.EVAL...\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-10-14:50:51\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_convnet_modellearningrate_0.1\\model.ckpt-41\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-10-14:50:54\n",
      "INFO:tensorflow:Saving dict for global step 41: accuracy = 0.5998, global_step = 41, loss = 1.0265918\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 41: ./mnist_convnet_modellearningrate_0.1\\model.ckpt-41\n",
      "EVAL EPOCH... 5\n",
      "{'accuracy': 0.5998, 'loss': 1.0265918, 'global_step': 41}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "x_input.shape (?, 28, 28, 1)\n",
      "convlayer1.shape (?, 28, 28, 16)\n",
      "maxpool1.shape (?, 14, 14, 16)\n",
      "convlayer2.shape (?, 14, 14, 16)\n",
      "maxpool2.shape (?, 7, 7, 16)\n",
      "maxpool2_vec.shape (?, 784)\n",
      "denselayer.shape (?, 128)\n",
      "logitslayer.shape (?, 10)\n",
      "labels.shape (?,)\n",
      "sceloss.shape ()\n",
      "tf.estimator.ModeKeys.EVAL...\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-10-14:50:54\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_convnet_modellearningrate_0.1\\model.ckpt-41\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-10-14:50:57\n",
      "INFO:tensorflow:Saving dict for global step 41: accuracy = 0.5844, global_step = 41, loss = 1.07029\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 41: ./mnist_convnet_modellearningrate_0.1\\model.ckpt-41\n",
      "{'lr': 0.1, 'num_filters': 16, 'batch_size': 128, 'filter_size': 3, 'learning_curve': [{'accuracy': 0.7505, 'loss': 0.9646816, 'global_step': 37}, {'accuracy': 0.78, 'loss': 0.8392948, 'global_step': 38}, {'accuracy': 0.787, 'loss': 0.7673814, 'global_step': 39}, {'accuracy': 0.7603, 'loss': 0.7737827, 'global_step': 40}, {'accuracy': 0.5998, 'loss': 1.0265918, 'global_step': 41}], 'test_error': {'accuracy': 0.5844, 'loss': 1.07029, 'global_step': 41}}\n"
     ]
    }
   ],
   "source": [
    "class JSONEnc(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(JSONEnc, self).default(obj)\n",
    "\n",
    "def one_hot(labels):\n",
    "    \"\"\"this creates a one hot encoding from a flat vector:\n",
    "    i.e. given y = [0,2,1]\n",
    "     it creates y_one_hot = [[1,0,0], [0,0,1], [0,1,0]]\n",
    "    \"\"\"\n",
    "    classes = np.unique(labels)\n",
    "    n_classes = classes.size\n",
    "    one_hot_labels = np.zeros(labels.shape + (n_classes,))\n",
    "    for c in classes:\n",
    "        one_hot_labels[labels == c, c] = 1\n",
    "    return one_hot_labels\n",
    "\n",
    "def unhot(one_hot_labels):\n",
    "    \"\"\" Invert a one hot encoding, creating a flat vector \"\"\"\n",
    "    return np.argmax(one_hot_labels, axis=-1)\n",
    "\n",
    "def mnist(datasets_dir='./data'):\n",
    "    if not os.path.exists(datasets_dir):\n",
    "        os.mkdir(datasets_dir)\n",
    "    data_file = os.path.join(datasets_dir, 'mnist.pkl.gz')\n",
    "    if not os.path.exists(data_file):\n",
    "        print('... downloading MNIST from the web')\n",
    "        try:\n",
    "            import urllib\n",
    "            urllib.urlretrieve('http://google.com')\n",
    "        except AttributeError:\n",
    "            import urllib.request as urllib\n",
    "        url = 'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz'\n",
    "        urllib.urlretrieve(url, data_file)\n",
    "\n",
    "    print('... loading data')\n",
    "    # Load the dataset\n",
    "    f = gzip.open(data_file, 'rb')\n",
    "    try:\n",
    "        train_set, valid_set, test_set = pickle.load(f, encoding=\"latin1\")\n",
    "    except TypeError:\n",
    "        train_set, valid_set, test_set = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    test_x, test_y = test_set\n",
    "    test_x = test_x.astype('float32')\n",
    "    test_x = test_x.astype('float32').reshape(test_x.shape[0], 28, 28, 1)\n",
    "    test_y = test_y.astype('int32')\n",
    "    valid_x, valid_y = valid_set\n",
    "    valid_x = valid_x.astype('float32')\n",
    "    valid_x = valid_x.astype('float32').reshape(valid_x.shape[0], 28, 28, 1)\n",
    "    valid_y = valid_y.astype('int32')\n",
    "    train_x, train_y = train_set\n",
    "    train_x = train_x.astype('float32').reshape(train_x.shape[0], 28, 28, 1)\n",
    "    train_y = train_y.astype('int32')\n",
    "    print('... done loading data')\n",
    "#     return train_x, one_hot(train_y), valid_x, one_hot(valid_y), test_x, one_hot(test_y)\n",
    "    return train_x, train_y, valid_x, valid_y, test_x, test_y\n",
    "\n",
    "# Using tf Estimators\n",
    "# Conv Net Function\n",
    "def build_cnn_model(features, labels, mode, params):\n",
    "    # STEP 1 : BUILD CONVNET\n",
    "    # GRAPH : I/P --> CL1 --> RELU --> POOL1 --> CL2 --> RELU --> POOL2 --> FC --> SOFTMAX\n",
    "    \n",
    "    # Hyperparameters\n",
    "    lr = params['lr']\n",
    "    num_filters = params['num_filters']\n",
    "    filter_size = params['filter_size']\n",
    "    \n",
    "    # Convolutional Layer #1\n",
    "    # Computes num_filters features using a filter_size*filter_size filter with ReLU activation.\n",
    "    # Padding is SAME\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "    # Output Tensor Shape: [batch_size, 28, 28, num_filters]\n",
    "    x_input = tf.reshape(features[\"x_ip\"], [-1, 28, 28, 1])\n",
    "    convlayer1 = tf.layers.conv2d(inputs=x_input, filters=num_filters, kernel_size=filter_size,\\\n",
    "                                  padding=\"same\", activation=tf.nn.relu)\n",
    "    # Pooling Layer #1\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, num_filters]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, num_filters]\n",
    "    maxpool1 = tf.layers.max_pooling2d(inputs=convlayer1, pool_size=2, strides=2)\n",
    "    \n",
    "    # Convolutional Layer #2\n",
    "    # Computes num_filters features using a filter_size*filter_size filter with ReLU activation.\n",
    "    # Padding is SAME\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, num_filters]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, num_filters]\n",
    "    convlayer2 = tf.layers.conv2d(inputs=maxpool1, filters=num_filters, kernel_size=filter_size,\\\n",
    "                                  padding=\"same\", activation=tf.nn.relu)\n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, num_filters]\n",
    "    # Output Tensor Shape: [batch_size, 7, 7, num_filters]\n",
    "    maxpool2 = tf.layers.max_pooling2d(inputs=convlayer2, pool_size=2, strides=2)\n",
    "    \n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 7, 7, num_filters]\n",
    "    # Output Tensor Shape: [batch_size, 7 * 7 * num_filters]\n",
    "#     maxpool2_vec = tf.reshape(maxpool2, [-1, 7 * 7 * num_filters])\n",
    "    maxpool2_vec = tf.reshape(maxpool2, [-1, maxpool2.shape[1] * maxpool2.shape[2] * num_filters])\n",
    "    \n",
    "    # Dense Layer\n",
    "    # Densely connected layer with 128 neurons\n",
    "    # Input Tensor Shape: [batch_size, 7 * 7 * num_filters]\n",
    "    # Output Tensor Shape: [batch_size, 128]\n",
    "    denselayer = tf.layers.dense(inputs=maxpool2_vec, units=128)\n",
    "    \n",
    "    # Logits Layer\n",
    "    logitslayer = tf.layers.dense(inputs=denselayer, units=10, activation=None)\n",
    "#     logits = tf.layers.dense(inputs=dropout, units=10)#size: [batch_size,10]\n",
    "\n",
    "    # Generate predictions (for PREDICT and EVAL mode)\n",
    "    predictions = { \"classes\": tf.argmax(input=logitslayer, axis=1),\\\n",
    "                   \"probabilities\": tf.nn.softmax(logitslayer, name=\"softmax_tensor\") }\n",
    "    \n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    sceloss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logitslayer)\n",
    "\n",
    "    ## SHAPE CHECK\n",
    "    print(\"x_input.shape\", x_input.shape)\n",
    "    print(\"convlayer1.shape\", convlayer1.shape)\n",
    "    print(\"maxpool1.shape\", maxpool1.shape)\n",
    "    print(\"convlayer2.shape\", convlayer2.shape)\n",
    "    print(\"maxpool2.shape\", maxpool2.shape)\n",
    "    print(\"maxpool2_vec.shape\", maxpool2_vec.shape)\n",
    "    print(\"denselayer.shape\", denselayer.shape)\n",
    "    print(\"logitslayer.shape\", logitslayer.shape)\n",
    "    print(\"labels.shape\", labels.shape)\n",
    "    print(\"sceloss.shape\", sceloss.shape)\n",
    "    \n",
    "    # Generate estimator object for TRAIN\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        print(\"tf.estimator.ModeKeys.TRAIN...\")\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "        train_op = optimizer.minimize(loss=sceloss,global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(tf.estimator.ModeKeys.TRAIN,loss=sceloss, train_op=train_op)\n",
    "    \n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL: \n",
    "        print(\"tf.estimator.ModeKeys.EVAL...\")\n",
    "        eval_metric_ops = { \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=sceloss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "def train_and_validate(x_train, y_train, x_valid, y_valid, num_epochs, lr, num_filters, batch_size, filter_size):\n",
    "    # TODO: train and validate your convolutional neural networks with the provided data and hyperparameters\n",
    "    learning_curve = []\n",
    "    param_dict = {'lr': lr, 'num_filters': num_filters, 'filter_size': filter_size,}\n",
    "    dir_name = \"./mnist_convnet_modellearningrate_\" + str(lr)\n",
    "    print(dir_name)\n",
    "    \n",
    "    # Logging Hook\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    log_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=10)\n",
    "    \n",
    "    # Create the Estimator\n",
    "    MNIST_estimator = tf.estimator.Estimator(model_fn=build_cnn_model, params=param_dict, model_dir=dir_name)\n",
    "    \n",
    "    # Training Param Func\n",
    "    train_func = tf.estimator.inputs.numpy_input_fn(x={\"x_ip\": x_train}, y=y_train, batch_size=batch_size,\\\n",
    "                                                    num_epochs=None, shuffle=True)\n",
    "    # Val Param Func\n",
    "    val_func = tf.estimator.inputs.numpy_input_fn(x={\"x_ip\": x_valid}, y=y_valid, num_epochs=1, shuffle=False)\n",
    "    \n",
    "    # Train & Validate the model/estimator\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        te = MNIST_estimator.train(input_fn=train_func, hooks=[log_hook], steps=1)\n",
    "        print(\"TRAINING EPOCH...\", epoch)\n",
    "        print(te)\n",
    "\n",
    "        ve = MNIST_estimator.evaluate(input_fn=val_func)\n",
    "        print(\"EVAL EPOCH...\", epoch)\n",
    "        print(ve)\n",
    "        learning_curve.append(ve)\n",
    "    \n",
    "    return learning_curve, MNIST_estimator  # TODO: Return the validation error after each epoch (i.e learning curve) and your model\n",
    "\n",
    "\n",
    "def test(x_test, y_test, model):\n",
    "    # TODO: test your network here by evaluating it on the test data\n",
    "    test_func = tf.estimator.inputs.numpy_input_fn(x={\"x_ip\": x_test}, y=y_test, num_epochs=1, shuffle=False)\n",
    "    test_err = model.evaluate(input_fn=test_func)\n",
    "    return test_err\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--output_path\", default=\"./\", type=str, nargs=\"?\",\n",
    "                        help=\"Path where the results will be stored\")\n",
    "    parser.add_argument(\"--input_path\", default=\"./\", type=str, nargs=\"?\",\n",
    "                        help=\"Path where the data is located. If the data is not available it will be downloaded first\")\n",
    "    parser.add_argument(\"--learning_rate\", default=1e-3, type=float, nargs=\"?\", help=\"Learning rate for SGD\")\n",
    "    parser.add_argument(\"--num_filters\", default=32, type=int, nargs=\"?\",\n",
    "                        help=\"The number of filters for each convolution layer\")\n",
    "    parser.add_argument(\"--batch_size\", default=128, type=int, nargs=\"?\", help=\"Batch size for SGD\")\n",
    "    parser.add_argument(\"--epochs\", default=12, type=int, nargs=\"?\",\n",
    "                        help=\"Determines how many epochs the network will be trained\")\n",
    "    parser.add_argument(\"--run_id\", default=0, type=int, nargs=\"?\",\n",
    "                        help=\"Helps to identify different runs of an experiments\")\n",
    "    parser.add_argument(\"--filter_size\", default=3, type=int, nargs=\"?\",\n",
    "                        help=\"Filter width and height\")\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "    # hyperparameters\n",
    "#     lr = args.learning_rate\n",
    "#     num_filters = args.num_filters\n",
    "#     batch_size = args.batch_size\n",
    "#     epochs = args.epochs\n",
    "#     filter_size = args.filter_size\n",
    "\n",
    "    base_path = \"./\"\n",
    "    \n",
    "    # hyperparameters\n",
    "    lrs = [0.1, 0.01, 0.001, 0.0001] #args.learning_rate\n",
    "    lr = lrs[0]\n",
    "    num_filters = 16 #args.num_filters\n",
    "    batch_size = 128 #args.batch_size\n",
    "    epochs = 5 #args.epochs\n",
    "    filter_size = 3 #args.filter_size\n",
    "\n",
    "    # train and test convolutional neural network\n",
    "#     x_train, y_train, x_valid, y_valid, x_test, y_test = mnist(args.input_path)\n",
    "    x_train, y_train, x_valid, y_valid, x_test, y_test = mnist(base_path)\n",
    "    \n",
    "    # SHAPE TEST\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(x_valid.shape)\n",
    "    print(y_valid.shape)\n",
    "    print(x_test.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    learning_curve, model = train_and_validate(x_train, y_train, x_valid, y_valid, epochs, lr, num_filters, \\\n",
    "                                               batch_size, filter_size)\n",
    "    test_error = test(x_test, y_test, model)\n",
    "\n",
    "    # save results in a dictionary and write them into a .json file\n",
    "    results = dict()\n",
    "    results[\"lr\"] = lr\n",
    "    results[\"num_filters\"] = num_filters\n",
    "    results[\"batch_size\"] = batch_size\n",
    "    results[\"filter_size\"] = filter_size\n",
    "    results[\"learning_curve\"] = learning_curve\n",
    "    results[\"test_error\"] = test_error\n",
    "\n",
    "    print(results)\n",
    "#     path = os.path.join(args.output_path, \"results\")\n",
    "    path = os.path.join(base_path, \"results\")\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "#     fname = os.path.join(path, \"results_run_%d.json\" % args.run_id)\n",
    "    fname = os.path.join(path, \"results_run_lr_%2f.json\" % lr)\n",
    "    fh = open(fname, \"w\")\n",
    "    json.dump(results, fh, cls=JSONEnc)\n",
    "    fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py 4 TF",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
